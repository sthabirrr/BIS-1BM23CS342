"""
Particle Swarm Optimization (PSO) — step-by-step script (matches your 1–7 list)

- Step 1: Define objective f(x) to MINIMIZE
- Step 2: Initialize hyperparameters (N, w, c1, c2, etc.)
- Step 3: Initialize particles (positions & velocities)
- Step 4: Evaluate fitness
- Step 5: Update velocities & positions
- Step 6: Iterate
- Step 7: Output best solution
"""

import numpy as np
import math

# -------------------------------
# 1) Define the Problem (objective)
# -------------------------------
def rastrigin(x: np.ndarray) -> float:
    """Multi-modal benchmark; global min at x=0 with value 0."""
    A = 10.0
    return A * x.size + np.sum(x**2 - A * np.cos(2 * np.pi * x))

# If you want to use your own objective, just replace `fitness_fn` below.
fitness_fn = rastrigin

# -------------------------------
# 2) Initialize Parameters
# -------------------------------
dim = 5                                  # dimensionality of x
bounds = np.array([[-5.12, 5.12]] * dim) # [lower, upper] for each dim
num_particles = 50
max_iters = 200
w = 0.72          # inertia weight
c1 = 1.6          # cognitive coefficient
c2 = 1.6          # social coefficient
seed = 7
rng = np.random.default_rng(seed)

lb, ub = bounds[:,0], bounds[:,1]
span = ub - lb
vmin, vmax = -0.25 * span, 0.25 * span   # optional velocity clipping

# -------------------------------
# 3) Initialize Particles
# -------------------------------
X = rng.uniform(lb, ub, size=(num_particles, dim))             # positions
V = rng.uniform(-0.2*span, 0.2*span, size=(num_particles, dim))# velocities

pbest_X = X.copy()                                  # personal best positions
pbest_val = np.full(num_particles, np.inf, float)   # personal best fitness
gbest_X = None                                      # global best position
gbest_val = math.inf                                # global best fitness

# -------------------------------
# 4) Evaluate Fitness (initial)
# -------------------------------
for i in range(num_particles):
    f = float(fitness_fn(X[i]))
    pbest_val[i] = f
    pbest_X[i] = X[i].copy()
    if f < gbest_val:
        gbest_val = f
        gbest_X = X[i].copy()

# -------------------------------
# 6) Iterate (evaluate + update)
# -------------------------------
history = [gbest_val]
for it in range(1, max_iters + 1):
    # (4) Evaluate & update personal/global bests
    for i in range(num_particles):
        f = float(fitness_fn(X[i]))
        if f < pbest_val[i]:
            pbest_val[i] = f
            pbest_X[i] = X[i].copy()
        if f < gbest_val:
            gbest_val = f
            gbest_X = X[i].copy()

    # (5) Update velocities and positions
    r1 = rng.random(size=(num_particles, dim))
    r2 = rng.random(size=(num_particles, dim))
    cognitive = c1 * r1 * (pbest_X - X)
    social    = c2 * r2 * (gbest_X - X)
    V = w * V + cognitive + social
    V = np.clip(V, vmin, vmax)                # optional velocity clipping
    X = np.clip(X + V, lb, ub)                # enforce bounds

    history.append(gbest_val)

# -------------------------------
# 7) Output the Best Solution
# -------------------------------
print("=== PSO Result ===")
print("Best x:", np.round(gbest_X, 6))
print("Best f(x):", gbest_val)
print(f"Iterations: {max_iters}, Particles: {num_particles}")
print("First 5 history values:", [round(h, 6) for h in history[:5]])
print("Last 5 history values :", [round(h, 6) for h in history[-5:]])
